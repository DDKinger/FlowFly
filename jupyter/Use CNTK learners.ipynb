{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cntk as C\n",
    "import numpy as np\n",
    "import math\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "features = C.input_variable(3)\n",
    "label = C.input_variable(2)\n",
    "z = C.layers.Sequential([C.layers.Dense(4, activation=C.relu), C.layers.Dense(2)])(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_learner_m = C.sgd(z.parameters, lr = 0.5, minibatch_size = C.learners.IGNORE)\n",
    "sgd_learner_s2 = C.sgd(z.parameters, lr = 0.5, minibatch_size = 2)\n",
    "lr = 0.01\n",
    "# sgd_learner_m = C.sgd(z.parameters, lr=C.learners.learning_parameter_schedule_per_sample(lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate per minibatch: 0.01\n",
      "Finished Epoch[1]: loss = 0.176705 * 100, metric = 0.00% * 100 0.028s (3571.4 samples/s);\n",
      "Finished Epoch[2]: loss = 0.175672 * 100, metric = 0.00% * 100 0.014s (7142.9 samples/s);\n",
      "Finished Epoch[3]: loss = 0.174976 * 100, metric = 0.00% * 100 0.018s (5555.6 samples/s);\n",
      "Finished Epoch[4]: loss = 0.174506 * 100, metric = 0.00% * 100 0.015s (6666.7 samples/s);\n",
      "Finished Epoch[5]: loss = 0.174188 * 100, metric = 0.00% * 100 0.014s (7142.9 samples/s);\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epoch_summaries': [{'loss': 0.17670473098754882,\n",
       "   'metric': 0.0,\n",
       "   'samples': 100},\n",
       "  {'loss': 0.1756724548339844, 'metric': 0.0, 'samples': 100},\n",
       "  {'loss': 0.17497642517089843, 'metric': 0.0, 'samples': 100},\n",
       "  {'loss': 0.17450614929199218, 'metric': 0.0, 'samples': 100},\n",
       "  {'loss': 0.17418766021728516, 'metric': 0.0, 'samples': 100}],\n",
       " 'updates': []}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "loss = C.squared_error(z, label)\n",
    "sgd_learner_my1 = C.sgd(z.parameters, lr=C.learners.learning_parameter_schedule([lr]*2+[lr/2]*3+[lr/4], epoch_size=2000))\n",
    "x_train = np.asarray(np.random.rand(100,3), dtype=np.float32)\n",
    "y_train = np.asarray(np.random.rand(100,2), dtype=np.float32)\n",
    "progress_writer = C.logging.ProgressPrinter()\n",
    "loss.train((x_train, y_train), minibatch_size=10, max_epochs=5, parameter_learners=[sgd_learner_my1], callbacks=[progress_writer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate per minibatch: 0.01\n",
      "Finished Epoch[6]: loss = 0.173835 * 100, metric = 0.00% * 100 23.794s (  4.2 samples/s);\n",
      "Finished Epoch[7]: loss = 0.173730 * 100, metric = 0.00% * 100 0.007s (14285.7 samples/s);\n",
      "Finished Epoch[8]: loss = 0.173670 * 100, metric = 0.00% * 100 0.006s (16666.7 samples/s);\n",
      "Finished Epoch[9]: loss = 0.173644 * 100, metric = 0.00% * 100 0.005s (20000.0 samples/s);\n",
      "Finished Epoch[10]: loss = 0.173646 * 100, metric = 0.00% * 100 0.006s (16666.7 samples/s);\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epoch_summaries': [{'loss': 0.17383459091186523,\n",
       "   'metric': 0.0,\n",
       "   'samples': 100},\n",
       "  {'loss': 0.17373039245605468, 'metric': 0.0, 'samples': 100},\n",
       "  {'loss': 0.17366983413696288, 'metric': 0.0, 'samples': 100},\n",
       "  {'loss': 0.17364423751831054, 'metric': 0.0, 'samples': 100},\n",
       "  {'loss': 0.17364635467529296, 'metric': 0.0, 'samples': 100}],\n",
       " 'updates': []}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_learner_my1 = C.sgd(z.parameters, lr=C.learners.learning_parameter_schedule([lr]*2+[lr/2]*3+[lr/4], epoch_size=2000))\n",
    "loss.train((x_train, y_train), max_epochs=5, parameter_learners=[sgd_learner_my1], callbacks=[progress_writer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate per minibatch: 0.01\n",
      "Finished Epoch[31]: loss = 0.173491 * 100, metric = 0.00% * 100 12.481s (  8.0 samples/s);\n",
      "Learning rate per minibatch: 0.005\n",
      "Finished Epoch[32]: loss = 0.173328 * 100, metric = 0.00% * 100 0.015s (6666.7 samples/s);\n",
      "Learning rate per minibatch: 0.0025\n",
      "Finished Epoch[33]: loss = 0.173348 * 100, metric = 0.00% * 100 0.016s (6250.0 samples/s);\n",
      "Finished Epoch[34]: loss = 0.173250 * 100, metric = 0.00% * 100 0.016s (6250.0 samples/s);\n",
      "Finished Epoch[35]: loss = 0.173249 * 100, metric = 0.00% * 100 0.015s (6666.7 samples/s);\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epoch_summaries': [{'loss': 0.1734906578063965,\n",
       "   'metric': 0.0,\n",
       "   'samples': 100},\n",
       "  {'loss': 0.1733275032043457, 'metric': 0.0, 'samples': 100},\n",
       "  {'loss': 0.17334751129150391, 'metric': 0.0, 'samples': 100},\n",
       "  {'loss': 0.17324975967407227, 'metric': 0.0, 'samples': 100},\n",
       "  {'loss': 0.17324859619140626, 'metric': 0.0, 'samples': 100}],\n",
       " 'updates': []}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_learner_my1 = C.sgd(z.parameters, lr=C.learners.learning_parameter_schedule([lr]*2+[lr/2]*3+[lr/4], epoch_size=50))\n",
    "loss.train((x_train, y_train), minibatch_size=10, max_epochs=5, parameter_learners=[sgd_learner_my1], callbacks=[progress_writer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate per 1 samples: 0.01\n",
      "Finished Epoch[36]: loss = 0.175562 * 100, metric = 0.00% * 100 34.232s (  2.9 samples/s);\n",
      "Learning rate per 1 samples: 0.005\n",
      "Finished Epoch[37]: loss = 0.174765 * 100, metric = 0.00% * 100 0.015s (6666.7 samples/s);\n",
      "Learning rate per 1 samples: 0.0025\n",
      "Finished Epoch[38]: loss = 0.174905 * 100, metric = 0.00% * 100 0.013s (7692.3 samples/s);\n",
      "Finished Epoch[39]: loss = 0.173936 * 100, metric = 0.00% * 100 0.016s (6250.0 samples/s);\n",
      "Finished Epoch[40]: loss = 0.173939 * 100, metric = 0.00% * 100 0.017s (5882.4 samples/s);\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epoch_summaries': [{'loss': 0.1755621337890625,\n",
       "   'metric': 0.0,\n",
       "   'samples': 100},\n",
       "  {'loss': 0.17476490020751953, 'metric': 0.0, 'samples': 100},\n",
       "  {'loss': 0.1749051284790039, 'metric': 0.0, 'samples': 100},\n",
       "  {'loss': 0.17393606185913085, 'metric': 0.0, 'samples': 100},\n",
       "  {'loss': 0.17393922805786133, 'metric': 0.0, 'samples': 100}],\n",
       " 'updates': []}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_learner_my1 = C.sgd(z.parameters, lr=C.learners.learning_parameter_schedule_per_sample([lr]*2+[lr/2]*3+[lr/4], epoch_size=50))\n",
    "loss.train((x_train, y_train), minibatch_size=10, max_epochs=5, parameter_learners=[sgd_learner_my1], callbacks=[progress_writer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_update(learner, actual_minibatch_size, count=1):\n",
    "    # Save current parameter values\n",
    "    old_values = [p.value for p in learner.parameters]\n",
    "#     print(\"old_values:\")\n",
    "#     print(old_values)\n",
    "    # Set current parameter values to all 0\n",
    "    for p in learner.parameters:\n",
    "        p.value = 0 * p.value\n",
    "    # create all-ones gradients, and associate the sum of gradients over\n",
    "    # the number of samples in the minibatch with the parameters\n",
    "    gradients_sum = {p: np.zeros_like(p.value)\n",
    "                     + 1.0 * actual_minibatch_size for p in learner.parameters}\n",
    "#     print(\"gradients_sum:\")\n",
    "#     print(gradients_sum)\n",
    "    # do 'count' many updates\n",
    "    for i in range(count):\n",
    "        # note that CNTK learner's update function consumes\n",
    "        # sum of gradients over the samples in a minibatch\n",
    "        learner.update(gradients_sum, actual_minibatch_size)\n",
    "    ret_values = [p.value for p in learner.parameters]\n",
    "#     print(\"ret_values:\")\n",
    "#     print(ret_values)\n",
    "    # Restore values\n",
    "    for p, o in zip(learner.parameters, old_values):\n",
    "        p.value = o\n",
    "#     print([p.value for p in learner.parameters])\n",
    "    return ret_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "per minibatch:\n",
      " [array([[-1., -1.],\n",
      "       [-1., -1.],\n",
      "       [-1., -1.],\n",
      "       [-1., -1.]], dtype=float32), array([-1., -1.], dtype=float32), array([[-1., -1., -1., -1.],\n",
      "       [-1., -1., -1., -1.],\n",
      "       [-1., -1., -1., -1.]], dtype=float32), array([-1., -1., -1., -1.], dtype=float32)]\n",
      "\n",
      "per samples: \n",
      " [array([[-5., -5.],\n",
      "       [-5., -5.],\n",
      "       [-5., -5.],\n",
      "       [-5., -5.]], dtype=float32), array([-5., -5.], dtype=float32), array([[-5., -5., -5., -5.],\n",
      "       [-5., -5., -5., -5.],\n",
      "       [-5., -5., -5., -5.]], dtype=float32), array([-5., -5., -5., -5.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print('\\nper minibatch:\\n', inspect_update(sgd_learner_m, actual_minibatch_size=10, count = 2))\n",
    "print('\\nper samples: \\n', inspect_update(sgd_learner_s2, actual_minibatch_size=10, count = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\Anaconda3\\lib\\site-packages\\cntk\\learners\\__init__.py:340: RuntimeWarning: When providing the schedule as a number, epoch_size is ignored\n",
      "  warnings.warn('When providing the schedule as a number, epoch_size is ignored', RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "lr=0.01\n",
    "sgd_learner_my1 = C.sgd(z.parameters, lr=C.learners.learning_parameter_schedule_per_sample([lr]*2+[lr/2]*3+[lr/4], epoch_size=256))\n",
    "sgd_learner_my2 = C.sgd(z.parameters, lr=C.learners.learning_parameter_schedule([lr]*2+[lr/2]*3+[lr/4], epoch_size=256))\n",
    "sgd_learner_my3 = C.sgd(z.parameters, lr=C.learners.learning_parameter_schedule(lr, epoch_size=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "per minibatch:\n",
      " [array([[-1.28, -1.28],\n",
      "       [-1.28, -1.28],\n",
      "       [-1.28, -1.28],\n",
      "       [-1.28, -1.28]], dtype=float32), array([-1.28, -1.28], dtype=float32), array([[-1.28, -1.28, -1.28, -1.28],\n",
      "       [-1.28, -1.28, -1.28, -1.28],\n",
      "       [-1.28, -1.28, -1.28, -1.28]], dtype=float32), array([-1.28, -1.28, -1.28, -1.28], dtype=float32)]\n",
      "\n",
      "per samples: \n",
      " [array([[-0.005, -0.005],\n",
      "       [-0.005, -0.005],\n",
      "       [-0.005, -0.005],\n",
      "       [-0.005, -0.005]], dtype=float32), array([-0.005, -0.005], dtype=float32), array([[-0.005, -0.005, -0.005, -0.005],\n",
      "       [-0.005, -0.005, -0.005, -0.005],\n",
      "       [-0.005, -0.005, -0.005, -0.005]], dtype=float32), array([-0.005, -0.005, -0.005, -0.005], dtype=float32)]\n",
      "\n",
      "per samples: \n",
      " [array([[-0.01, -0.01],\n",
      "       [-0.01, -0.01],\n",
      "       [-0.01, -0.01],\n",
      "       [-0.01, -0.01]], dtype=float32), array([-0.01, -0.01], dtype=float32), array([[-0.01, -0.01, -0.01, -0.01],\n",
      "       [-0.01, -0.01, -0.01, -0.01],\n",
      "       [-0.01, -0.01, -0.01, -0.01]], dtype=float32), array([-0.01, -0.01, -0.01, -0.01], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\nper minibatch:\\n', inspect_update(sgd_learner_my1, actual_minibatch_size=256, count = 1))\n",
    "print('\\nper samples: \\n', inspect_update(sgd_learner_my2, actual_minibatch_size=256, count = 1))\n",
    "print('\\nper samples: \\n', inspect_update(sgd_learner_my3, actual_minibatch_size=256, count = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256*0.01/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_values:\n",
      "[array([[-1.2322, -1.2272],\n",
      "       [-0.5976, -1.458 ],\n",
      "       [-0.7982,  0.3227],\n",
      "       [-0.5585, -1.3511]], dtype=float32), array([-0.5, -0.5], dtype=float32), array([[-1.1299,  0.4113, -1.3526, -0.3195],\n",
      "       [-0.4217, -1.32  , -0.2565, -0.6415],\n",
      "       [ 0.1337,  0.2523, -0.6423, -0.212 ]], dtype=float32), array([-0.5, -0.5, -0.5, -0.5], dtype=float32)]\n",
      "gradients_sum:\n",
      "{Parameter('W', [], [4 x 2]): array([[2., 2.],\n",
      "       [2., 2.],\n",
      "       [2., 2.],\n",
      "       [2., 2.]], dtype=float32), Parameter('b', [], [2]): array([2., 2.], dtype=float32), Parameter('W', [], [3 x 4]): array([[2., 2., 2., 2.],\n",
      "       [2., 2., 2., 2.],\n",
      "       [2., 2., 2., 2.]], dtype=float32), Parameter('b', [], [4]): array([2., 2., 2., 2.], dtype=float32)}\n",
      "ret_values:\n",
      "[array([[-0.5, -0.5],\n",
      "       [-0.5, -0.5],\n",
      "       [-0.5, -0.5],\n",
      "       [-0.5, -0.5]], dtype=float32), array([-0.5, -0.5], dtype=float32), array([[-0.5, -0.5, -0.5, -0.5],\n",
      "       [-0.5, -0.5, -0.5, -0.5],\n",
      "       [-0.5, -0.5, -0.5, -0.5]], dtype=float32), array([-0.5, -0.5, -0.5, -0.5], dtype=float32)]\n",
      "[array([[-1.2322, -1.2272],\n",
      "       [-0.5976, -1.458 ],\n",
      "       [-0.7982,  0.3227],\n",
      "       [-0.5585, -1.3511]], dtype=float32), array([-0.5, -0.5], dtype=float32), array([[-1.1299,  0.4113, -1.3526, -0.3195],\n",
      "       [-0.4217, -1.32  , -0.2565, -0.6415],\n",
      "       [ 0.1337,  0.2523, -0.6423, -0.212 ]], dtype=float32), array([-0.5, -0.5, -0.5, -0.5], dtype=float32)]\n",
      "\n",
      "per minibatch:\n",
      " [array([[-0.5, -0.5],\n",
      "       [-0.5, -0.5],\n",
      "       [-0.5, -0.5],\n",
      "       [-0.5, -0.5]], dtype=float32), array([-0.5, -0.5], dtype=float32), array([[-0.5, -0.5, -0.5, -0.5],\n",
      "       [-0.5, -0.5, -0.5, -0.5],\n",
      "       [-0.5, -0.5, -0.5, -0.5]], dtype=float32), array([-0.5, -0.5, -0.5, -0.5], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print('\\nper minibatch:\\n', inspect_update(sgd_learner_m, actual_minibatch_size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "per 2 samples: \n",
      " [array([[-0.5, -0.5],\n",
      "       [-0.5, -0.5],\n",
      "       [-0.5, -0.5],\n",
      "       [-0.5, -0.5]], dtype=float32), array([-0.5, -0.5], dtype=float32), array([[-0.5, -0.5, -0.5, -0.5],\n",
      "       [-0.5, -0.5, -0.5, -0.5],\n",
      "       [-0.5, -0.5, -0.5, -0.5]], dtype=float32), array([-0.5, -0.5, -0.5, -0.5], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print('\\nper 2 samples: \\n', inspect_update(sgd_learner_s2, actual_minibatch_size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "per minibatch:\n",
      " [array([[-0.5, -0.5],\n",
      "       [-0.5, -0.5],\n",
      "       [-0.5, -0.5],\n",
      "       [-0.5, -0.5]], dtype=float32), array([-0.5, -0.5], dtype=float32), array([[-0.5, -0.5, -0.5, -0.5],\n",
      "       [-0.5, -0.5, -0.5, -0.5],\n",
      "       [-0.5, -0.5, -0.5, -0.5]], dtype=float32), array([-0.5, -0.5, -0.5, -0.5], dtype=float32)]\n",
      "\n",
      "per 10 samples: \n",
      " [array([[-2.5, -2.5],\n",
      "       [-2.5, -2.5],\n",
      "       [-2.5, -2.5],\n",
      "       [-2.5, -2.5]], dtype=float32), array([-2.5, -2.5], dtype=float32), array([[-2.5, -2.5, -2.5, -2.5],\n",
      "       [-2.5, -2.5, -2.5, -2.5],\n",
      "       [-2.5, -2.5, -2.5, -2.5]], dtype=float32), array([-2.5, -2.5, -2.5, -2.5], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print('\\nper minibatch:\\n', inspect_update(sgd_learner_m, actual_minibatch_size=10))\n",
    "print('\\nper 10 samples: \\n', inspect_update(sgd_learner_s2, actual_minibatch_size=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd : [-30. -30.]\n",
      "tsgd : [-357.4343 -357.4343]\n",
      "adadelta : [-0.0297 -0.0297]\n",
      "adagrad  : [-30. -30.]\n",
      "adam     : [-32.3197 -32.3197]\n",
      "adamax   : [-32.3276 -32.3276]\n",
      "fsadagrad: [-63.1707 -63.1707]\n",
      "rmsprop  : [-30. -30.]\n",
      "adadelta2: [-29.7969 -29.7969]\n"
     ]
    }
   ],
   "source": [
    "mb_size = 32\n",
    "\n",
    "lr_schedule = C.learning_parameter_schedule(1, minibatch_size=C.learners.IGNORE)\n",
    "t_schedule = C.momentum_schedule(0.971, minibatch_size=C.learners.IGNORE)\n",
    "\n",
    "sgd = C.sgd(z.parameters, lr_schedule)\n",
    "tsgd = C.momentum_sgd(z.parameters, lr_schedule, t_schedule, unit_gain=False)\n",
    "adadelta  = C.adadelta(z.parameters, lr_schedule, 0.999, 1e-6)\n",
    "adagrad   = C.adagrad(z.parameters, lr_schedule)\n",
    "adam      = C.adam(z.parameters, lr_schedule, t_schedule, unit_gain=False)\n",
    "adamax    = C.adam(z.parameters, lr_schedule, t_schedule, unit_gain=False, adamax=True)\n",
    "fsadagrad = C.fsadagrad(z.parameters, lr_schedule, t_schedule, unit_gain=False)\n",
    "rmsprop   = C.rmsprop(z.parameters, lr_schedule, gamma=0.999, inc=1.0+1e-9, dec=1.0-1e-9, max=np.inf, min=1e-30)\n",
    "\n",
    "num_steps = 30\n",
    "print('sgd :', inspect_update(sgd, mb_size, num_steps)[0][0])\n",
    "print('tsgd :', inspect_update(tsgd, mb_size, num_steps)[0][0])\n",
    "print('adadelta :', inspect_update(adadelta, mb_size, num_steps)[0][0])\n",
    "print('adagrad  :', inspect_update(adagrad, mb_size, num_steps)[0][0])\n",
    "print('adam     :', inspect_update(adam, mb_size, num_steps)[0][0])\n",
    "print('adamax   :', inspect_update(adamax, mb_size, num_steps)[0][0])\n",
    "print('fsadagrad:', inspect_update(fsadagrad, mb_size, num_steps)[0][0])\n",
    "print('rmsprop  :', inspect_update(rmsprop, mb_size, num_steps)[0][0])\n",
    "\n",
    "adadelta_schedule = C.learning_parameter_schedule(1004, minibatch_size=C.learners.IGNORE)\n",
    "adadelta_tuned  = C.adadelta(z.parameters, adadelta_schedule, 0.999, 1e-6)\n",
    "print('adadelta2:', inspect_update(adadelta_tuned, mb_size, num_steps)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.7322, -0.7272],\n",
       "        [-0.0976, -0.958 ],\n",
       "        [-0.2982,  0.8227],\n",
       "        [-0.0585, -0.8511]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[-0.6299,  0.9113, -0.8526,  0.1805],\n",
       "        [ 0.0783, -0.82  ,  0.2435, -0.1415],\n",
       "        [ 0.6337,  0.7523, -0.1423,  0.288 ]], dtype=float32),\n",
       " array([0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.value for p in sgd_learner_m.parameters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Parameter('W', [], [3 x 4]): array([[2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2.]], dtype=float32),\n",
       " Parameter('W', [], [4 x 2]): array([[2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.]], dtype=float32),\n",
       " Parameter('b', [], [2]): array([2., 2.], dtype=float32),\n",
       " Parameter('b', [], [4]): array([2., 2., 2., 2.], dtype=float32)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_minibatch_size = 2\n",
    "gradients_sum={p: np.zeros_like(p.value) + 1.0 * actual_minibatch_size for p in sgd_learner_m.parameters}\n",
    "gradients_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.2322, -1.2272],\n",
       "        [-0.5976, -1.458 ],\n",
       "        [-0.7982,  0.3227],\n",
       "        [-0.5585, -1.3511]], dtype=float32),\n",
       " array([-0.5, -0.5], dtype=float32),\n",
       " array([[-1.1299,  0.4113, -1.3526, -0.3195],\n",
       "        [-0.4217, -1.32  , -0.2565, -0.6415],\n",
       "        [ 0.1337,  0.2523, -0.6423, -0.212 ]], dtype=float32),\n",
       " array([-0.5, -0.5, -0.5, -0.5], dtype=float32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_learner_m.update(gradients_sum, actual_minibatch_size)\n",
    "[p.value for p in sgd_learner_m.parameters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "lrs = C.learners.learning_parameter_schedule_per_sample([lr]*20+[lr/2]*30+[lr/4], epoch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_learner = C.sgd(z.parameters, [0.05]*3 + [0.025]*2 + [0.0125], epoch_size=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
